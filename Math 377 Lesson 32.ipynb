{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datascience import *\n",
    "import numpy as np\n",
    "from numpy import random\n",
    "import pandas as pd\n",
    "from math import *\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lesson 32: Likelihood Ratio Tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Last time, we introduced Likelihood Ratio tests. Recall that the point of a likelihood ratio test is to compare the likelihood function under a hypothesized value of the parameter with the liklihood function at its maximum. Instead of looking at the ratio $\\Lambda$ itself, we often consider $-2\\log \\Lambda$ instead, since it has a handy distribution. \n",
    "\n",
    "### Example 1: Exponential Distribution\n",
    "\n",
    "Suppose $X_1,X_2,...,X_n$ is an iid sequence of random variables from the exponential distribution with unknown parameter $\\lambda$. Recall that the maximum likelihood estimate of $\\lambda$ is $1\\over\\bar{X}$. We collect a random sample of size 20 and want to test the hypothesis $H_0: \\lambda = 3$ vs $H_1: \\lambda \\neq 3$. Using the data in the python box below, conduct a likelihood ratio test on this hypothesis.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_data=np.array([0.18,0.277,0.105,0.126,0.225,0.026,0.123,0.423,0.006,0.281,0.050,0.692,0.105,0.275,0.346,0.079,0.045,0.222,0.063,0.281])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our maximum likelihood estimate of lambda for this draw is 5.089058524173028\n"
     ]
    }
   ],
   "source": [
    "xbar = np.mean(my_data)\n",
    "print(\"Our maximum likelihood estimate of lambda for this draw is\", 1/xbar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lambda is 5.089058524173028\n",
      "Max Liklihood of the data is 279807.44620464457\n",
      "Under null hypothesis, max likelihood is 26429.755940265666 , but how weird is this?\n"
     ]
    }
   ],
   "source": [
    "lambda_ML = 1/xbar\n",
    "print(\"Lambda is\", lambda_ML)\n",
    "likelihood_ML = np.prod(lambda_ML * e**(-lambda_ML * my_data))\n",
    "print(\"Max Liklihood of the data is\", likelihood_ML)\n",
    "null_likelihood = np.prod(3 * e**(-3*my_data))\n",
    "print(\"Under null hypothesis, max likelihood is\", null_likelihood, \", but how weird is this?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p-value: 0.02982722919477517\n"
     ]
    }
   ],
   "source": [
    "capital_lambda = null_likelihood / likelihood_ML\n",
    "log_lambda = -2*log(capital_lambda)\n",
    "p_value = stats.chi2.sf(log_lambda, 1)\n",
    "print(\"p-value:\", p_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With a p-value of 0.0298, we can conclude that it is very unlikely that lambda would be equal to 3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Power\n",
    "\n",
    "Suppose that the true value of $\\lambda$ is 5. Let's determine the power of this test. Let $n=20$. Then determine the power if $n=50$. Remember, power is the probability of correctly rejecting the null hypothesis. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, find what value of $-2 \\log \\Lambda$ would lead you to reject $H_0$. This is sometimes called the critical value. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.841458820694124"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crit=stats.chi2.ppf(0.95, 1)\n",
    "crit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*...So 3.84 is the threshold of weirdness. Anything above this we reject, anything below we fail to reject and say it could have viably happened by chance.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, obtain the power. Obtain a sample of size 20 from the true population and obtain the value of $-2\\log \\Lambda$ for this sample. Repeat many times and determine how often you reject the null hypothesis. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5946"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values = np.array([])\n",
    "n = 20\n",
    "\n",
    "for _ in np.arange(10000):\n",
    "    data = stats.expon.rvs(scale=1/5, size=n)\n",
    "    lam = 1 / np.mean(data)\n",
    "    null_lh = np.prod(3 * e**(-3*data))\n",
    "    max_lh = np.prod(lam * e**(-lam*data))\n",
    "    cap_lam = null_lh / max_lh\n",
    "    log_lam = -2*log(cap_lam)\n",
    "    values = np.append(values, log_lam)\n",
    "    \n",
    "np.mean(values>=crit)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Repeat for a sample size of 50. What do you expect to happen to power? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p-value 0.9524\n"
     ]
    }
   ],
   "source": [
    "# I expect power to increase\n",
    "lamvals = np.array([])\n",
    "n = 50\n",
    "lam_0 = 3\n",
    "\n",
    "for _ in np.arange(10000):\n",
    "    sample_data = stats.expon.rvs(scale=1/5, size=n)\n",
    "    lam_new = 1/np.mean(sample_data)\n",
    "    null_lh = np.prod(lam_0 * e**(-lam_0*sample_data))\n",
    "    max_lh = np.prod(lam_new * e**(-lam_new*sample_data))\n",
    "    cap_lam = null_lh / max_lh\n",
    "    log_lam = -2*log(cap_lam)\n",
    "    lamvals = np.append(lamvals, log_lam)\n",
    "    \n",
    "p_val = np.mean(lamvals >= crit)\n",
    "print(\"p-value\", p_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A Different Test\n",
    "\n",
    "We've explored hypothesis tests in this class before. Taking advantage of our computing power, we don't have to rely on test statistics with asymptotic distributions. Let's conduct a more direct hypothesis test using simulation. Recall:\n",
    "\n",
    "$$\n",
    "H_0: \\lambda = 3\n",
    "$$\n",
    "\n",
    "$$\n",
    "H_1: \\lambda \\neq 3\n",
    "$$\n",
    "\n",
    "Pick a different test statistic. Obtain an empirical distribution of that test statistic under $H_0$. Next, find the $p$-value by determining how often this test statistic is at or further away from the test statistic derived from the sample. Remember that this is a two-sided test. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.70477062 2.32382541]\n",
      "p-value 0.054\n"
     ]
    }
   ],
   "source": [
    "test_stats = np.array([])\n",
    "n = 1000\n",
    "lam_0 = 3\n",
    "\n",
    "# Test stat will be difference between lam_new and lam_0\n",
    "for _ in np.arange(10000):\n",
    "    sample_data = stats.expon.rvs(scale=1/5, size=n)\n",
    "    lam_new = 1/np.mean(sample_data)\n",
    "    test_stat = lam_new - lam_0\n",
    "    test_stats = np.append(test_stats, test_stat)\n",
    "\n",
    "print(percentile([2.5, 97.5], test_stats))\n",
    "print(\"p-value\", np.mean(test_stats<1.7097) + np.mean(test_stats>2.3196))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How did the $p$-value compare to the LRT $p$-value? I wonder how the power of this test compares to our LRT. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This p-value is much smaller, but still small enough that we reject the null hypothesis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Power\n",
    "\n",
    "Let's figure out the power of this test. First, determine for what values of the test statistic would lead us to reject $H_0$. These values can be referred to as your rejection region. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.86738375, 3.71917905])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "percentile([2.5, 97.5], test_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, determine the power of this test. Like in the LRT case, obtain a sample of size 20 and obtain the test statistic. Repeat many times and see how often your test statistic is in your rejection region. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.38663494 5.1689812 ]\n",
      "p-value 0.0463\n"
     ]
    }
   ],
   "source": [
    "test_stats = np.array([])\n",
    "n = 20\n",
    "lam_0 = 3\n",
    "\n",
    "# Test stat will be difference between lam_new and lam_0\n",
    "for _ in np.arange(10000):\n",
    "    sample_data = stats.expon.rvs(scale=1/5, size=n)\n",
    "    lam_new = 1/np.mean(sample_data)\n",
    "    test_stat = lam_new - lam_0\n",
    "    test_stats = np.append(test_stats, test_stat)\n",
    "\n",
    "print(percentile([2.5, 97.5], test_stats))\n",
    "print(\"p-value\", np.mean(test_stats<0.34456) + np.mean(test_stats>5.1299))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Repeat for a sample size of 50. Note that you will have to obtain new critical values in order to do this.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.86674933 3.79348595]\n",
      "p-value 0.0523\n"
     ]
    }
   ],
   "source": [
    "test_stats = np.array([])\n",
    "n = 50\n",
    "lam_0 = 3\n",
    "\n",
    "# Test stat will be difference between lam_new and lam_0\n",
    "for _ in np.arange(10000):\n",
    "    sample_data = stats.expon.rvs(scale=1/5, size=n)\n",
    "    lam_new = 1/np.mean(sample_data)\n",
    "    test_stat = lam_new - lam_0\n",
    "    test_stats = np.append(test_stats, test_stat)\n",
    "\n",
    "print(percentile([2.5, 97.5], test_stats))\n",
    "print(\"p-value\", np.mean(test_stats>3.7788) + np.mean(test_stats<0.8793))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
